{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet maison n° 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. US baby names\n",
    "\n",
    "On va s'intéresser au dataset **National data** de la SSA : https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "1. Télécharger le dataset des prénoms US : https://www.ssa.gov/oact/babynames/names.zip\n",
    "\n",
    "Lire la documentation associée.\n",
    "\n",
    "2. Implémenter une fonction Python qui produit un unique DataFrame avec tous les fichiers en utilisant pandas (par ex. fonction \"concat\" ou méthode \"append\"), pas de bash :)\n",
    "\n",
    "Ordre et noms des colonnes : 'year', 'name', 'gender', 'births'\n",
    "\n",
    "Le DataFrame doit être trié selon l'année croissante puis selon l'ordre défini par les différents fichiers (voir la documentation du dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names us\n",
    "\n",
    "path_prefix = \"/home/vsoking/Downloads/names/yob\"\n",
    "\n",
    "def df_names_us():\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(1880, 2021, 1):\n",
    "        path = path_prefix + str(i) + \".txt\"\n",
    "        tmp_df = pd.read_csv(path, names=[\"name\", \"gender\", \"births\"])\n",
    "        tmp_df[\"year\"] = i\n",
    "        df = df.append(tmp_df)\n",
    "        df.index = pd.RangeIndex(len(df.index))\n",
    "    return df[[\"year\", \"name\", \"gender\", \"births\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    1192115\n",
       "M     828748\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prénoms français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset **Fichiers France hors Mayotte** de l'INSEE :  https://www.insee.fr/fr/statistiques/2540004/\n",
    "\n",
    "L'idée est de charger les données et ensuite de les conformer au DataFrame des prénoms US. Ainsi, toute manipulation sur le DataFrame des prénoms US pourra être directement réutilisée avec le DataFrame des prénoms français.\n",
    " \n",
    "1. Télécharger le dataset des prénoms français : https://www.insee.fr/fr/statistiques/fichier/2540004/nat2020_csv.zip\n",
    "\n",
    "\n",
    "Lire la documentation, ça peut être utile...\n",
    " \n",
    "2. Implémenter une fonction Python qui produit un DataFrame avec les prénoms français en prenant le DataFrame des prénoms US comme modèle :\n",
    " \n",
    " - Même ordre et mêmes noms des colonnes : year, name, gender, births\n",
    " - Mêmes dtypes pour les colonnes\n",
    " - Mêmes valeurs pour la colonne 'gender'\n",
    " - Seuls les prénoms de 2 caractères et plus sont conservés\n",
    " - La casse des prénoms doit être identique : initiales en majuscule, autres lettres en minuscule\n",
    " - Les lignes avec des données inutilisables doivent être supprimées\n",
    " - Les données sont triées à l'identique : années (↑), puis gender (↑), puis births (↓) et enfin name (↑)\n",
    " - L'index du DataFrame doit aller de 0 à N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 630406 entries, 0 to 630405\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   year    630406 non-null  int64 \n",
      " 1   name    630406 non-null  object\n",
      " 2   gender  630406 non-null  object\n",
      " 3   births  630406 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 19.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# names fr\n",
    "def df_names_fr():\n",
    "    df = pd.read_csv(\"/home/vsoking/Downloads/nat2020.csv\", delimiter=';', header=0,\n",
    "                     names=[\"gender\", \"name\", \"year\", \"births\"])\n",
    "    \n",
    "    #Mêmes dtypes pour les colonnes\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors='coerce')\n",
    "    \n",
    "    #Mêmes valeurs pour la colonne 'gender'\n",
    "    df[\"gender\"] = df[\"gender\"].map({1:'M', 2:'F'})\n",
    "    \n",
    "    #Les lignes avec des données inutilisables doivent être supprimées\n",
    "    df = df.dropna()\n",
    "    \n",
    "    #Mêmes dtypes pour les colonnes\n",
    "    df[\"year\"] = df[\"year\"].astype('int64')\n",
    "    \n",
    "    #Seuls les prénoms de 2 caractères et plus sont conservés\n",
    "    df = df.loc[df[\"name\"].str.len() >=2]\n",
    "    \n",
    "    df = df.loc[~df[\"name\"].str.contains(\"_Prenoms_Rares\", case=False)]\n",
    "    \n",
    "    #La casse des prénoms doit être identique \n",
    "    df[\"name\"] = df[\"name\"].str.title()\n",
    "    \n",
    "    #Les données sont triées à l'identique    \n",
    "    df.sort_values([\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True], inplace=True)\n",
    "    \n",
    "    #L'index du DataFrame doit aller de 0 à N-1\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #Même ordre et mêmes noms des colonnes\n",
    "    return df[[\"year\", \"name\", \"gender\", \"births\"]]\n",
    "\n",
    "d = df_names_fr()\n",
    "d.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taux de change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset des cours des devises de la Banque de France :  http://webstat.banque-france.fr/fr/#/downloading\n",
    "\n",
    "L'idée est de charger les données, de les nettoyer et de pouvoir accéder aux cours de certaines devises à partir de leur code ISO3.\n",
    " \n",
    "1. Utiliser le dataset des taux de change fourni.\n",
    "\n",
    "\n",
    "2. Implémenter une fonction qui produit un DataFrame avec les taux de change par date pour une liste de codes ISO3 de devises passée en argument. L'index du DataFrame doit correspondre aux dates (voir la fonction pd.to_datetime() avec le format '%d/%m/%Y'). Les colonnes du DataFrame doivent correspondre aux devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 214 entries, 01/10/2016 to 01/01/1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   EXR.M.CYP.EUR.SP00.A  108 non-null    object\n",
      " 1   EXR.M.CYP.EUR.SP00.E  108 non-null    object\n",
      " 2   EXR.M.EEK.EUR.SP00.A  144 non-null    object\n",
      " 3   EXR.M.EEK.EUR.SP00.E  144 non-null    object\n",
      " 4   EXR.M.LTL.EUR.SP00.A  172 non-null    object\n",
      " 5   EXR.M.LTL.EUR.SP00.E  172 non-null    object\n",
      " 6   EXR.M.LVL.EUR.SP00.A  159 non-null    object\n",
      " 7   EXR.M.LVL.EUR.SP00.E  159 non-null    object\n",
      " 8   EXR.M.MTL.EUR.SP00.A  87 non-null     object\n",
      " 9   EXR.M.MTL.EUR.SP00.E  87 non-null     object\n",
      " 10  EXR.M.SDD.EUR.SP00.E  85 non-null     object\n",
      " 11  EXR.M.SIT.EUR.SP00.A  96 non-null     object\n",
      " 12  EXR.M.SIT.EUR.SP00.E  96 non-null     object\n",
      " 13  EXR.M.SKK.EUR.SP00.A  99 non-null     object\n",
      " 14  EXR.M.SKK.EUR.SP00.E  99 non-null     object\n",
      " 15  EXR.M.SYP.EUR.SP00.E  201 non-null    object\n",
      " 16  EXR.M.TMM.EUR.SP00.E  107 non-null    object\n",
      " 17  EXR.M.VEB.EUR.SP00.E  95 non-null     object\n",
      " 18  EXR.M.ZMK.EUR.SP00.E  156 non-null    object\n",
      " 19  EXR.M.ZWD.EUR.SP00.E  25 non-null     object\n",
      " 20  EXR.M.ZWR.EUR.SP00.E  3 non-null      object\n",
      "dtypes: object(21)\n",
      "memory usage: 36.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# taux de change\n",
    "def df_taux_change(devises):\n",
    "    #df = pd.read_csv(\"/home/vsoking/Downloads/Taux_de_change_mensuel_(Archive).csv\", delimiter=';', header=2)\n",
    "    df = pd.read_csv(\"/home/vsoking/Downloads/Taux_de_change_mensuel_(Archive).csv\", delimiter=';', \n",
    "                 header=1, encoding = \"ISO-8859-1\", index_col=0, skiprows=[2,3,4,5])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.astype(float, errors='ignore')\n",
    "    df = pd.DataFrame([], columns=devises)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"/home/vsoking/Downloads/Taux_de_change_mensuel_(Archive).csv\", delimiter=';', \n",
    "                 header=1, encoding = \"ISO-8859-1\", index_col=0, skiprows=[2,3,4,5])\n",
    "df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Lesson4Tests(unittest.TestCase):\n",
    "    def test_df_names_us(self):\n",
    "        df = df_names_us()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 2020863)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "        \n",
    "    def test_df_names_fr(self):\n",
    "        df = df_names_fr()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 630407)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test names\n",
    "        self.assertTrue(df.loc[df['name'].str.contains('^[A-Z]+(?:-[A-Z]+)?$')].empty)\n",
    "        # test gender\n",
    "        self.assertEqual(len(df), len(df.loc[df['gender']=='F']) + len(df.loc[df['gender']=='M']))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "\n",
    "    def test_df_taux_change(self):\n",
    "        df = df_taux_change(['CHF', 'GBP', 'USD'])\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['CHF', 'GBP', 'USD'])\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex))\n",
    "        # types taux\n",
    "        self.assertTrue((df.dtypes == 'float').all())\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson4Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_df_names_fr (__main__.Lesson4Tests) ... ok\n",
      "test_df_names_us (__main__.Lesson4Tests) ... ok\n",
      "test_df_taux_change (__main__.Lesson4Tests) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_df_taux_change (__main__.Lesson4Tests)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-257-e90acbc5238c>\", line 37, in test_df_taux_change\n",
      "    self.assertTrue((df.dtypes == 'float').all())\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 5.546s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
